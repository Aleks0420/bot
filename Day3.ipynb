{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/Koziev/NLP_Datasets/blob/master/Conversations/Data/dialogues.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dialogues.txt',  encoding=\"utf-8\") as f:\n",
    "    content = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1034007"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(content.split('\\n\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialogues = []  # [[Q, A], ...]\n",
    "\n",
    "for dialogue_text in content.split('\\n\\n'):\n",
    "    replicas = dialogue_text.split('\\n')\n",
    "    if len(replicas) >= 2:\n",
    "        replicas = replicas[:2]\n",
    "        replicas = [replica[2:] for replica in replicas]\n",
    "        replicas[0] = replicas[0].lower().strip()\n",
    "        if replicas[0]:\n",
    "            dialogues.append(tuple(replicas))\n",
    "\n",
    "dialogues = list(set(dialogues))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "718276\n",
      "[('думитрашка! ты больше смотри в книгу, чем на лиду.', 'Что случилось, Иван?'), ('почему вы не заходите? тут есть чем взбодриться.', 'Поймал чертова наркомана!'), ('ну, а ты, малютка? выпила хинную настойку?', 'Да, барышня, Выпила.'), ('смотрите, окружают!', 'А где же другие наши суда?'), ('пропуск!', 'Вроде не ты?'), ('я найду сковородку, на которой тебя поджарить,', 'Омлет недоделанный.'), ('вижу две чаши!', 'Вижу, что видишь!'), ('туда, месиво из соленой пади лежало вместе.', 'Мешки, Шевелиться, рожи не кривить!'), ('в патронах не картечь, а круглые пули.', 'Черт побери, Назарова там нет.'), ('минутку, проф, не отключайтесь.', 'Вайо?')]\n"
     ]
    }
   ],
   "source": [
    "print(len(dialogues))\n",
    "print(dialogues[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\W9641\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_dataset = {}\n",
    "\n",
    "alphabet = 'йцукенгшщзхъфывапролджэёячсмитьбю'\n",
    "for question, answer in dialogues:\n",
    "    tokens = nltk.word_tokenize(question)\n",
    "    words = [token for token in tokens if any(char in token for char in alphabet)]\n",
    "    for word in words:\n",
    "        if word not in qa_dataset:\n",
    "            qa_dataset[word] = []\n",
    "        qa_dataset[word].append((question, answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generative_answer(text):\n",
    "    text = text.lower()\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    words = [token for token in tokens if any(char in token for char in alphabet)]\n",
    "    for word in words:\n",
    "        if word in qa_dataset:\n",
    "            for question, answer in qa_dataset[word]:\n",
    "                if abs(len(text) - len(question)) / len(question) < 0.2:\n",
    "                    distance = nltk.edit_distance(text, question)\n",
    "                    if distance / len(question) < 0.2:\n",
    "                        return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Пятьсот тысяч!'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_generative_answer('сколько вес')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Привет\n",
    "Добрый день"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
